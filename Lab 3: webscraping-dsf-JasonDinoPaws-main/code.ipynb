{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fonts.gstatic.com:\n",
      "Sub: fonts\n",
      "SDL: gstatic\n",
      "TDL: com\n",
      "\n",
      "fonts.googleapis.com:\n",
      "Sub: fonts\n",
      "SDL: googleapis\n",
      "TDL: com\n",
      "\n",
      "www.googletagmanager.com:\n",
      "Sub: www\n",
      "SDL: googletagmanager\n",
      "TDL: com\n",
      "\n",
      "cookiehub.net:\n",
      "Sub: cookiehub\n",
      "SDL: \n",
      "TDL: net\n",
      "\n",
      "www.google-analytics.com:\n",
      "Sub: www\n",
      "SDL: google-analytics\n",
      "TDL: com\n",
      "\n",
      "google-analytics.bi.owox.com:\n",
      "Sub: google-analytics\n",
      "SDL: bi.owox\n",
      "TDL: com\n",
      "\n",
      "widget.intercom.io:\n",
      "Sub: widget\n",
      "SDL: intercom\n",
      "TDL: io\n",
      "\n",
      "streaming.bi.owox.com:\n",
      "Sub: streaming\n",
      "SDL: bi.owox\n",
      "TDL: com\n",
      "\n",
      "www.google.com:\n",
      "Sub: www\n",
      "SDL: google\n",
      "TDL: com\n",
      "\n",
      "ad.doubleclick.net:\n",
      "Sub: ad\n",
      "SDL: doubleclick\n",
      "TDL: net\n",
      "\n",
      "a.quora.com:\n",
      "Sub: a\n",
      "SDL: quora\n",
      "TDL: com\n",
      "\n",
      "snap.licdn.com:\n",
      "Sub: snap\n",
      "SDL: licdn\n",
      "TDL: com\n",
      "\n",
      "bat.bing.com:\n",
      "Sub: bat\n",
      "SDL: bing\n",
      "TDL: com\n",
      "\n",
      "connect.facebook.net:\n",
      "Sub: connect\n",
      "SDL: facebook\n",
      "TDL: net\n",
      "\n",
      "munchkin.marketo.net:\n",
      "Sub: munchkin\n",
      "SDL: marketo\n",
      "TDL: net\n",
      "\n",
      "analytics.tiktok.com:\n",
      "Sub: analytics\n",
      "SDL: tiktok\n",
      "TDL: com\n",
      "\n",
      "s.yimg.com:\n",
      "Sub: s\n",
      "SDL: yimg\n",
      "TDL: com\n",
      "\n",
      "q.quora.com:\n",
      "Sub: q\n",
      "SDL: quora\n",
      "TDL: com\n",
      "\n",
      "www.facebook.com:\n",
      "Sub: www\n",
      "SDL: facebook\n",
      "TDL: com\n",
      "\n",
      "s.amazon-adsystem.com:\n",
      "Sub: s\n",
      "SDL: amazon-adsystem\n",
      "TDL: com\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = \"https://semrush.com\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Gets Any link type elements from page\n",
    "for l in soup.findAll(\"link\"):\n",
    "    # Gets the href of the element and removes the (https://| http://)\n",
    "    l = l.get(\"href\")\n",
    "    pro = len(l.split(\"//\",1)[0])+2\n",
    "    \n",
    "    # if the protocal was corredt would continue forward\n",
    "    if pro == 8:\n",
    "        l = l[pro:].split(\"/\",1)[0]\n",
    "\n",
    "        # If the length of the link was more that 0 after remove the path\n",
    "        if len(l) > 0:\n",
    "            sub = l.split(\".\",1)[0]\n",
    "            TLD = l.split(\".\")[-1]\n",
    "            SDL = l[len(sub)+1:l.find(TLD)-1]\n",
    "\n",
    "            if f\"{SDL}.{TLD}\" != \"semrush.com\":\n",
    "                print(f\"{l}:\\nSub: {sub}\\nSDL: {SDL}\\nTDL: {TLD}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu 08 50°/28°\n",
      "\n",
      "Fri 09 43°/27°\n",
      "\n",
      "Sat 10 32°/20°\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page = requests.get(\"https://weather.com/weather/tenday/l/Littleton+CO?canonicalCityId=fdf4c3d397c75000204ff2ba1b9e9fa4adb284a0bf750f25ad6cd43c96cf9090\")\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "c = 0\n",
    "# Finds all the div tpye elements that have the class \n",
    "for l in soup.find_all(\"div\",class_=\"DetailsSummary--DetailsSummary--1DqhO DetailsSummary--fadeOnOpen--KnNyF\"):\n",
    "    # Gets the Data and the tempatures\n",
    "    Date = l.find(\"h3\")\n",
    "    High = l.find(\"span\",class_=\"DetailsSummary--highTempValue--3PjlX\")\n",
    "    Low = l.find(\"span\",class_=\"DetailsSummary--lowTempValue--2tesQ\")\n",
    "    \n",
    "    # checks if it has the 3 elements and if it wasnt today and past the next 3 days\n",
    "    if Date and High and Low and Date.text != \"Today\" and c < 3:\n",
    "        c += 1\n",
    "        print(f\"{Date} {High}/{Low}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miso Glazed Chicken Wings\n",
      "Prep Time: 10 mins\n",
      "Cook Time: 30 mins\n",
      "Total Time: 40 mins\n",
      "Servings: 4 servings\n",
      "\n",
      "Ingredients\n",
      " - 1 to 1 1/2 pounds chicken wings \n",
      " - 2 tablespoons miso paste \n",
      " - 2 tablespoons teriyaki sauce \n",
      " - 2 tablespoons rice wine vinegar \n",
      " - 1 tablespoon gochujang \n",
      " - Green onions Green onions Green onions \n",
      "\n",
      "Nutrition Facts\n",
      "Calories: 599\n",
      "Fat: 42g\n",
      "Carbs: 24g\n",
      "Protein: 31g\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page = requests.get(\"https://www.simplyrecipes.com/recipes/miso_glazed_chicken_wings/\")\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "print(soup.find(\"h2\",\"comp recipe-block__header text-block\").text.strip())\n",
    "\n",
    "# Prints out any elements under the class \"comp meta-text\"\n",
    "for l in soup.find_all(\"span\",\"comp meta-text\"):\n",
    "    Title = l.find(class_ = 'meta-text__label')\n",
    "    data = l.find(class_ = 'meta-text__data')\n",
    "\n",
    "    if Title and data:\n",
    "        print(f\"{Title.text}: {data.text}\")\n",
    "\n",
    "\n",
    "# Prints out all elements under class \"structured-ingredients__list text-passage\"\n",
    "# Then goes thought all of the list items \n",
    "print(\"\\nIngredients\")\n",
    "for l in soup.find_all(\"ul\",\"structured-ingredients__list text-passage\"):\n",
    "    for t in l.find_all(\"li\",\"structured-ingredients__list-item\"):\n",
    "        print(\" - \",end=\"\")\n",
    "        for item in t.find(\"p\").find_all(\"span\"):\n",
    "            print(item.text,end=\" \")\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "# Prints out all elements under \"Nutrition Facts\"\n",
    "print(\"\\nNutrition Facts\")\n",
    "for l in soup.find_all(\"tr\",class_=\"nutrition-info__table--row\"):\n",
    "    Nu = \"\"\n",
    "    \n",
    "    # Goes tough all of the elements in the nutrition facts\n",
    "    for chi in l.find_all(\"td\",class_=\"nutrition-info__table--cell\"):\n",
    "        Nu += (chi.text).strip()+\"|\"\n",
    "\n",
    "    # Fact: Amount\n",
    "    print(f\"{Nu.split('|')[1]}: {Nu.split('|')[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
